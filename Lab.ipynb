{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alexnet Data from: \n",
    "https://d17h27t6h515a5.cloudfront.net/topher/2016/October/580a829f_train/train.p\n",
    "\n",
    "Weights from: \n",
    "https://d17h27t6h515a5.cloudfront.net/topher/2016/October/580d880c_bvlc-alexnet/bvlc-alexnet.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alexnet Inference  \n",
    "Using the model as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0\n",
      "miniature poodle: 0.389\n",
      "toy poodle: 0.223\n",
      "Bedlington terrier: 0.173\n",
      "standard poodle: 0.150\n",
      "komondor: 0.026\n",
      "\n",
      "Image 1\n",
      "weasel: 0.331\n",
      "polecat, fitch, foulmart, foumart, Mustela putorius: 0.280\n",
      "black-footed ferret, ferret, Mustela nigripes: 0.210\n",
      "mink: 0.081\n",
      "Arctic fox, white fox, Alopex lagopus: 0.027\n",
      "\n",
      "Time: 0.022 seconds\n"
     ]
    }
   ],
   "source": [
    "# NOTE: You don't need to edit this code.\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.misc import imread\n",
    "from caffe_classes import class_names\n",
    "from alexnet import AlexNet\n",
    "\n",
    "\n",
    "# placeholders\n",
    "x = tf.placeholder(tf.float32, (None, 227, 227, 3))\n",
    "\n",
    "# By keeping `feature_extract` set to `False`\n",
    "# we indicate to keep the 1000 class final layer\n",
    "# originally used to train on ImageNet.\n",
    "probs = AlexNet(x, feature_extract=False)\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Read Images\n",
    "im1 = (imread(\"poodle.png\")[:, :, :3]).astype(np.float32)\n",
    "im1 = im1 - np.mean(im1)\n",
    "\n",
    "im2 = (imread(\"weasel.png\")[:, :, :3]).astype(np.float32)\n",
    "im2 = im2 - np.mean(im2)\n",
    "\n",
    "# Run Inference\n",
    "t = time.time()\n",
    "output = sess.run(probs, feed_dict={x: [im1, im2]})\n",
    "\n",
    "# Print Output\n",
    "for input_im_ind in range(output.shape[0]):\n",
    "    inds = np.argsort(output)[input_im_ind, :]\n",
    "    print(\"Image\", input_im_ind)\n",
    "    for i in range(5):\n",
    "        print(\"%s: %.3f\" % (class_names[inds[-1 - i]], output[input_im_ind, inds[-1 - i]]))\n",
    "    print()\n",
    "\n",
    "print(\"Time: %.3f seconds\" % (time.time() - t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Sign Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0\n",
      "screen, CRT screen: 0.051\n",
      "digital clock: 0.041\n",
      "laptop, laptop computer: 0.030\n",
      "balance beam, beam: 0.027\n",
      "parallel bars, bars: 0.023\n",
      "\n",
      "Image 1\n",
      "digital watch: 0.395\n",
      "digital clock: 0.275\n",
      "bottlecap: 0.115\n",
      "stopwatch, stop watch: 0.104\n",
      "combination lock: 0.086\n",
      "\n",
      "Time: 0.022 seconds\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The traffic signs are 32x32 so you\n",
    "have to resize them to be 227x227 before\n",
    "passing them to AlexNet.\n",
    "\"\"\"\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.misc import imread\n",
    "from caffe_classes import class_names\n",
    "from alexnet import AlexNet\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "# TODO: Resize the images so they can be fed into AlexNet.\n",
    "# HINT: Use `tf.image.resize_images` to resize the images\n",
    "resized = tf.image.resize_images(x, (227, 227))\n",
    "\n",
    "probs = AlexNet(resized)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Read Images\n",
    "im1 = imread(\"construction.jpg\").astype(np.float32)\n",
    "im1 = im1 - np.mean(im1)\n",
    "\n",
    "im2 = imread(\"stop.jpg\").astype(np.float32)\n",
    "im2 = im2 - np.mean(im2)\n",
    "\n",
    "# Run Inference\n",
    "t = time.time()\n",
    "output = sess.run(probs, feed_dict={x: [im1, im2]})\n",
    "\n",
    "# Print Output\n",
    "for input_im_ind in range(output.shape[0]):\n",
    "    inds = np.argsort(output)[input_im_ind, :]\n",
    "    print(\"Image\", input_im_ind)\n",
    "    for i in range(5):\n",
    "        print(\"%s: %.3f\" % (class_names[inds[-1 - i]], output[input_im_ind, inds[-1 - i]]))\n",
    "    print()\n",
    "\n",
    "print(\"Time: %.3f seconds\" % (time.time() - t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0\n",
      "No passing: 0.672\n",
      "Road narrows on the right: 0.328\n",
      "Ahead only: 0.000\n",
      "Double curve: 0.000\n",
      "Speed limit (50km/h): 0.000\n",
      "\n",
      "Image 1\n",
      "End of all speed and passing limits: 1.000\n",
      "Pedestrians: 0.000\n",
      "General caution: 0.000\n",
      "Go straight or left: 0.000\n",
      "Children crossing: 0.000\n",
      "\n",
      "Time: 0.362 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "from alexnet import AlexNet\n",
    "\n",
    "sign_names = pd.read_csv('signnames.csv')\n",
    "nb_classes = 43\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "resized = tf.image.resize_images(x, (227, 227))\n",
    "\n",
    "# NOTE: By setting `feature_extract` to `True` we return\n",
    "# the second to last layer.\n",
    "fc7 = AlexNet(resized, feature_extract=True)\n",
    "# TODO: Define a new fully connected layer followed by a softmax activation to classify\n",
    "# the traffic signs. Assign the result of the softmax activation to `probs` below.\n",
    "# HINT: Look at the final layer definition in alexnet.py to get an idea of what this\n",
    "# should look like.\n",
    "shape = (fc7.get_shape().as_list()[-1], nb_classes)  # use this shape for the weight matrix\n",
    "# fc8\n",
    "# fc(1000, relu=False, name='fc8')\n",
    "fc8W = tf.Variable(tf.truncated_normal(shape, stddev=1e-2))\n",
    "fc8b = tf.Variable(tf.zeros(nb_classes))\n",
    "logits = tf.nn.xw_plus_b(fc7, fc8W, fc8b)\n",
    "probs = tf.nn.softmax(logits)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Read Images\n",
    "im1 = imread(\"construction.jpg\").astype(np.float32)\n",
    "im1 = im1 - np.mean(im1)\n",
    "\n",
    "im2 = imread(\"stop.jpg\").astype(np.float32)\n",
    "im2 = im2 - np.mean(im2)\n",
    "\n",
    "# Run Inference\n",
    "t = time.time()\n",
    "output = sess.run(probs, feed_dict={x: [im1, im2]})\n",
    "\n",
    "# Print Output\n",
    "for input_im_ind in range(output.shape[0]):\n",
    "    inds = np.argsort(output)[input_im_ind, :]\n",
    "    print(\"Image\", input_im_ind)\n",
    "    for i in range(5):\n",
    "        print(\"%s: %.3f\" % (sign_names.ix[inds[-1 - i]][1], output[input_im_ind, inds[-1 - i]]))\n",
    "    print()\n",
    "\n",
    "print(\"Time: %.3f seconds\" % (time.time() - t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on top of feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Dataset: 38.8MB [00:04, 9.29MB/s]                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Test data downloaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Load traffic signs data.\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('train.p'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='Train Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://s3.amazonaws.com/udacity-sdc/datasets/german_traffic_sign_benchmark/train.p',\n",
    "            'train.p',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isfile('test.p'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='Test Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://s3.amazonaws.com/udacity-sdc/datasets/german_traffic_sign_benchmark/test.p',\n",
    "            'test.p',\n",
    "            pbar.hook)\n",
    "\n",
    "print('Training and Test data downloaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# TODO: Split data into training and validation sets.\n",
    "with open('train.p', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# TODO: Load the feature data to the variable X_train\n",
    "X_train = data['features']\n",
    "\n",
    "# TODO: Load the label data to the variable y_train\n",
    "y_train = data['labels']\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Define placeholders and resize operation.\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "from alexnet import AlexNet\n",
    "\n",
    "sign_names = pd.read_csv('signnames.csv')\n",
    "nb_classes = 43\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "resized = tf.image.resize_images(x, (227,227))\n",
    "\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, nb_classes)\n",
    "\n",
    "# TODO: pass placeholder as first argument to `AlexNet`.\n",
    "fc7 = AlexNet(resized, feature_extract=True)\n",
    "# NOTE: `tf.stop_gradient` prevents the gradient from flowing backwards\n",
    "# past this point, keeping the weights before and up to `fc7` frozen.\n",
    "# This also makes training faster, less work to do!\n",
    "fc7 = tf.stop_gradient(fc7)\n",
    "\n",
    "# TODO: Add the final layer for traffic sign classification.\n",
    "shape = (fc7.get_shape().as_list()[-1], nb_classes)\n",
    "fc8_w = tf.Variable(tf.truncated_normal(shape, stddev=1e-2))\n",
    "fc8_b = tf.Variable(tf.zeros(nb_classes))\n",
    "logits = tf.nn.xw_plus_b(fc7, fc8_w, fc8_b)\n",
    "# probs = tf.nn.softmax(logits)\n",
    "\n",
    "# TODO: Define loss, training, accuracy operations.\n",
    "# HINT: Look back at your traffic signs project solution, you may\n",
    "# be able to reuse some the code.\n",
    "rate = 0.001\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits, one_hot_y)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Train and evaluate the feature extraction model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1: Validation Accuracy = 0.876\n",
      "EPOCH 2: Validation Accuracy = 0.913\n",
      "EPOCH 3: Validation Accuracy = 0.949\n",
      "EPOCH 4: Validation Accuracy = 0.955\n",
      "EPOCH 5: Validation Accuracy = 0.956\n",
      "EPOCH 6: Validation Accuracy = 0.964\n",
      "EPOCH 7: Validation Accuracy = 0.967\n",
      "EPOCH 8: Validation Accuracy = 0.970\n",
      "EPOCH 9: Validation Accuracy = 0.971\n",
      "EPOCH 10: Validation Accuracy = 0.973\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "\n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "        validation_accuracy = evaluate(X_validation, y_validation)\n",
    "        print(\"EPOCH {}: Validation Accuracy = {:.3f}\".format(i+1, validation_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
